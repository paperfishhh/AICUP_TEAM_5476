{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1dXVNEapVTH_SN2MDZKwROC6w-XUrSYmN","timestamp":1717902923022}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup\n","Install dependencies (requires restart)"],"metadata":{"id":"1cv_wqtK3M9M"}},{"cell_type":"code","source":["!pip install cython_bbox faiss-cpu faiss-gpu yacs lap numpy==1.23"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":671},"id":"D-xVjs_T3WMW","executionInfo":{"status":"ok","timestamp":1718008799655,"user_tz":-480,"elapsed":26926,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"c50917df-17d2-4b8f-822c-eb1ac8bcd052"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting cython_bbox\n","  Downloading cython_bbox-0.1.5.tar.gz (4.4 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yacs\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Collecting numpy==1.23\n","  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from cython_bbox) (3.0.10)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs) (6.0.1)\n","Building wheels for collected packages: cython_bbox\n","  Building wheel for cython_bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cython_bbox: filename=cython_bbox-0.1.5-cp310-cp310-linux_x86_64.whl size=99133 sha256=8b94b4ea657b322637401ae9d807913bad9623cf9cb5ba04d01c90ef6807ee3d\n","  Stored in directory: /root/.cache/pip/wheels/c0/b7/68/bab98b7180cda501101a57fb7d36884218ad45ec60c27cd679\n","Successfully built cython_bbox\n","Installing collected packages: faiss-gpu, yacs, numpy, faiss-cpu, cython_bbox\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.0 which is incompatible.\n","pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.0 which is incompatible.\n","tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.23.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cython_bbox-0.1.5 faiss-cpu-1.8.0 faiss-gpu-1.7.2 numpy-1.23.0 yacs-0.1.8\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"255d2814a73b4ec59a8578978f0033a8"}},"metadata":{}}]},{"cell_type":"markdown","source":["Clone baseline code\n"],"metadata":{"id":"66tpJdEzDQgu"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOt6_4sR1UJS","executionInfo":{"status":"ok","timestamp":1718008830899,"user_tz":-480,"elapsed":2854,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"44bbdb05-0f75-48e3-d74a-ff8cb512c700"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'AICUP_Baseline_BoT-SORT'...\n","remote: Enumerating objects: 1208, done.\u001b[K\n","remote: Counting objects: 100% (379/379), done.\u001b[K\n","remote: Compressing objects: 100% (261/261), done.\u001b[K\n","remote: Total 1208 (delta 172), reused 121 (delta 118), pack-reused 829\u001b[K\n","Receiving objects: 100% (1208/1208), 56.13 MiB | 38.52 MiB/s, done.\n","Resolving deltas: 100% (381/381), done.\n"]}],"source":["!git clone https://github.com/ricky-696/AICUP_Baseline_BoT-SORT.git"]},{"cell_type":"markdown","source":["Download and apply patches"],"metadata":{"id":"peXl1dVI3ztH"}},{"cell_type":"code","source":["%cd /content/AICUP_Baseline_BoT-SORT/yolov7/data\n","!rm AICUP.yaml\n","!wget -O AICUP.yaml https://www.dropbox.com/scl/fi/0ir7v7c1njxbmy1cxbs5u/AICUP.yaml?rlkey=va3uqeuvk6ttam5rap7k5yqr8&st=r5kejnhz&dl=1\n","%cd /content/AICUP_Baseline_BoT-SORT/fast_reid/fastreid/data\n","!rm build.py\n","!wget -O build.py https://www.dropbox.com/scl/fi/3pa2oemd3pmemy37fawvc/build.py?rlkey=5vgp2yi8qvlmb6toffde82mmm&st=bqit3uf5&dl=1\n","%cd /content/AICUP_Baseline_BoT-SORT/fast_reid/fastreid/evaluation\n","!rm testing.py\n","!wget -O testing.py https://www.dropbox.com/scl/fi/mo8p2henpw5ddk9bsbqqu/testing.py?rlkey=zkmllage8kw7gg8n6qrfolu0y&st=r2wax6nd&dl=1\n","%cd /content/AICUP_Baseline_BoT-SORT/fast_reid/configs/AICUP\n","!rm bagtricks_R50-ibn.yml\n","!wget -O bagtricks_R50-ibn.yml https://www.dropbox.com/scl/fi/08j5s65vt6g0jjcpbbney/bagtricks_R50-ibn.yml?rlkey=5x1feyax8gg7iij413lasl2q3&st=alqv3jo0&dl=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZccB5Ph3xDI","executionInfo":{"status":"ok","timestamp":1718009947535,"user_tz":-480,"elapsed":3769,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"6a32fa3b-6574-4069-88d6-6e8b98472af7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/AICUP_Baseline_BoT-SORT/yolov7/data\n","--2024-06-10 08:59:03--  https://www.dropbox.com/scl/fi/0ir7v7c1njxbmy1cxbs5u/AICUP.yaml?rlkey=va3uqeuvk6ttam5rap7k5yqr8\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc36ce02be46aac013227f7bd572.dl.dropboxusercontent.com/cd/0/inline/CUjDFQpbV4wP4I07170zMVlzsIksRaTrHlQNADFXqT29IrCMgN_-C3TFsD2u_NHpxNOXPSJ3Pap1xQ04NmKs2oKuYatjS8hzHB6Sj1vzoG1WqqpE8fIAqV58XgZAS5oLnzGVoipkE3GW0yjvJxu31BCr/file# [following]\n","--2024-06-10 08:59:04--  https://uc36ce02be46aac013227f7bd572.dl.dropboxusercontent.com/cd/0/inline/CUjDFQpbV4wP4I07170zMVlzsIksRaTrHlQNADFXqT29IrCMgN_-C3TFsD2u_NHpxNOXPSJ3Pap1xQ04NmKs2oKuYatjS8hzHB6Sj1vzoG1WqqpE8fIAqV58XgZAS5oLnzGVoipkE3GW0yjvJxu31BCr/file\n","Resolving uc36ce02be46aac013227f7bd572.dl.dropboxusercontent.com (uc36ce02be46aac013227f7bd572.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to uc36ce02be46aac013227f7bd572.dl.dropboxusercontent.com (uc36ce02be46aac013227f7bd572.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 274 [text/plain]\n","Saving to: ‘AICUP.yaml’\n","\n","AICUP.yaml          100%[===================>]     274  --.-KB/s    in 0s      \n","\n","2024-06-10 08:59:04 (116 MB/s) - ‘AICUP.yaml’ saved [274/274]\n","\n","/content/AICUP_Baseline_BoT-SORT/fast_reid/fastreid/data\n","--2024-06-10 08:59:04--  https://www.dropbox.com/scl/fi/3pa2oemd3pmemy37fawvc/build.py?rlkey=5vgp2yi8qvlmb6toffde82mmm\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucbc0568679ab83b5bfb765cff51.dl.dropboxusercontent.com/cd/0/inline/CUhNhTXzZ0asAzER3nLiiT94ixmIb12toWpebz5AMMm-08Iv9v5dRM-n9rPrMJYgSmKZUcKGSucmIzbie-2bv_ZFlXuYwkTsSLe1AGyYYVvPoKsAy9gZuf3kKzmJqRUShylYXGI_Y1g5hazkZQyP_Uqb/file# [following]\n","--2024-06-10 08:59:04--  https://ucbc0568679ab83b5bfb765cff51.dl.dropboxusercontent.com/cd/0/inline/CUhNhTXzZ0asAzER3nLiiT94ixmIb12toWpebz5AMMm-08Iv9v5dRM-n9rPrMJYgSmKZUcKGSucmIzbie-2bv_ZFlXuYwkTsSLe1AGyYYVvPoKsAy9gZuf3kKzmJqRUShylYXGI_Y1g5hazkZQyP_Uqb/file\n","Resolving ucbc0568679ab83b5bfb765cff51.dl.dropboxusercontent.com (ucbc0568679ab83b5bfb765cff51.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to ucbc0568679ab83b5bfb765cff51.dl.dropboxusercontent.com (ucbc0568679ab83b5bfb765cff51.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6234 (6.1K) [text/plain]\n","Saving to: ‘build.py’\n","\n","build.py            100%[===================>]   6.09K  --.-KB/s    in 0s      \n","\n","2024-06-10 08:59:05 (1.82 GB/s) - ‘build.py’ saved [6234/6234]\n","\n","/content/AICUP_Baseline_BoT-SORT/fast_reid/fastreid/evaluation\n","--2024-06-10 08:59:05--  https://www.dropbox.com/scl/fi/mo8p2henpw5ddk9bsbqqu/testing.py?rlkey=zkmllage8kw7gg8n6qrfolu0y\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc31a00b456ff2a247e6b27d4814.dl.dropboxusercontent.com/cd/0/inline/CUjw8DXagKOQh6Kg_Z2Z65Bgu4s_1_j2DsEtY9gV_nlqScs_moKo0MpA8jQoAxdOPP1QZ86n9Av5teAD7OURXvIUKKU7vurK4bKAVyTnmE72jNl7xz64KZEu_ok4zY3AT-j9xDbQaW7ITD0KcZNDuO3N/file# [following]\n","--2024-06-10 08:59:05--  https://uc31a00b456ff2a247e6b27d4814.dl.dropboxusercontent.com/cd/0/inline/CUjw8DXagKOQh6Kg_Z2Z65Bgu4s_1_j2DsEtY9gV_nlqScs_moKo0MpA8jQoAxdOPP1QZ86n9Av5teAD7OURXvIUKKU7vurK4bKAVyTnmE72jNl7xz64KZEu_ok4zY3AT-j9xDbQaW7ITD0KcZNDuO3N/file\n","Resolving uc31a00b456ff2a247e6b27d4814.dl.dropboxusercontent.com (uc31a00b456ff2a247e6b27d4814.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to uc31a00b456ff2a247e6b27d4814.dl.dropboxusercontent.com (uc31a00b456ff2a247e6b27d4814.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2451 (2.4K) [text/plain]\n","Saving to: ‘testing.py’\n","\n","testing.py          100%[===================>]   2.39K  --.-KB/s    in 0s      \n","\n","2024-06-10 08:59:06 (759 MB/s) - ‘testing.py’ saved [2451/2451]\n","\n","/content/AICUP_Baseline_BoT-SORT/fast_reid/configs/AICUP\n","--2024-06-10 08:59:06--  https://www.dropbox.com/scl/fi/08j5s65vt6g0jjcpbbney/bagtricks_R50-ibn.yml?rlkey=5x1feyax8gg7iij413lasl2q3\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc094e4c4dad5eff7e671d331643.dl.dropboxusercontent.com/cd/0/inline/CUhP3DbVHqUJhPQtkALV2VG9rm7Af6ie5WuESdsfH6cCBGvXPPtY-LOhowSgR5EvTMntGV2dhdarhJqCy0t_3NAi_Gbaw1QsWP4ovnAJZNb25_zS5R2DNe2a1uOSKrf7l-yFGkEpj7pseDAPYtvfgzLE/file# [following]\n","--2024-06-10 08:59:06--  https://uc094e4c4dad5eff7e671d331643.dl.dropboxusercontent.com/cd/0/inline/CUhP3DbVHqUJhPQtkALV2VG9rm7Af6ie5WuESdsfH6cCBGvXPPtY-LOhowSgR5EvTMntGV2dhdarhJqCy0t_3NAi_Gbaw1QsWP4ovnAJZNb25_zS5R2DNe2a1uOSKrf7l-yFGkEpj7pseDAPYtvfgzLE/file\n","Resolving uc094e4c4dad5eff7e671d331643.dl.dropboxusercontent.com (uc094e4c4dad5eff7e671d331643.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to uc094e4c4dad5eff7e671d331643.dl.dropboxusercontent.com (uc094e4c4dad5eff7e671d331643.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 568 [text/plain]\n","Saving to: ‘bagtricks_R50-ibn.yml’\n","\n","bagtricks_R50-ibn.y 100%[===================>]     568  --.-KB/s    in 0s      \n","\n","2024-06-10 08:59:06 (231 MB/s) - ‘bagtricks_R50-ibn.yml’ saved [568/568]\n","\n"]}]},{"cell_type":"markdown","source":["Mount your drive and decompress dataset archive (might take a while)"],"metadata":{"id":"UPT8g-JdDqVA"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"6rrkj2VI9c-2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718008865365,"user_tz":-480,"elapsed":16374,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"c0d0092e-fdb4-4ed6-a7ce-5dadd5c41c0b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!mkdir /content/AI_CUP_MCMOT_dataset\n","%cd /content/AI_CUP_MCMOT_dataset\n","!unzip -q /content/drive/MyDrive/32_33_train_v2.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iWz36GxeB5Uw","executionInfo":{"status":"ok","timestamp":1718009030070,"user_tz":-480,"elapsed":149035,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"6675e9d2-fa61-4796-8ff5-3ec16b596968"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/AI_CUP_MCMOT_dataset\n"]}]},{"cell_type":"markdown","source":["# Training\n","Prepare pretrained dataset"],"metadata":{"id":"zbsUe5lrHv7Z"}},{"cell_type":"code","source":["%cd /content/AICUP_Baseline_BoT-SORT/\n","!python fast_reid/datasets/generate_AICUP_patches.py --data_path /content/AI_CUP_MCMOT_dataset/train\n","!python yolov7/tools/AICUP_to_YOLOv7.py --AICUP_dir /content/AI_CUP_MCMOT_dataset/train --YOLOv7_dir /content/AI_CUP_MCMOT_dataset/yolo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G20C43DsH4Y6","executionInfo":{"status":"ok","timestamp":1718009620565,"user_tz":-480,"elapsed":570457,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"22258a25-4b0c-4f7c-85b6-46b0fe11328b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/AICUP_Baseline_BoT-SORT\n","convert /content/AI_CUP_MCMOT_dataset/train/images/0902_150000_151900: 100% 2880/2880 [00:44<00:00, 65.38it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/0902_190000_191900: 100% 2880/2880 [00:33<00:00, 84.89it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/0903_150000_151900: 100% 1081/1081 [00:14<00:00, 72.86it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/0903_190000_191900: 100% 2520/2520 [00:31<00:00, 80.98it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/0924_150000_151900: 100% 2786/2786 [00:46<00:00, 59.35it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/0924_190000_191900: 100% 2520/2520 [00:34<00:00, 73.63it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/0925_150000_151900: 100% 2880/2880 [00:47<00:00, 60.04it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/0925_190000_191900: 100% 2880/2880 [00:41<00:00, 70.08it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/1015_150000_151900: 100% 2880/2880 [00:45<00:00, 62.85it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/1015_190000_191900: 100% 2880/2880 [00:38<00:00, 74.38it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/1016_150000_151900: 100% 2880/2880 [00:46<00:00, 61.83it/s]\n","convert /content/AI_CUP_MCMOT_dataset/train/images/1016_190000_191900: 100% 2880/2880 [00:38<00:00, 74.23it/s]\n","copying data: 100% 63894/63894 [01:41<00:00, 627.83it/s] \n","delete_track_id: 100% 23307/23307 [00:02<00:00, 10574.87it/s]\n","delete_track_id: 100% 8640/8640 [00:00<00:00, 11397.49it/s]\n"]}]},{"cell_type":"markdown","source":["Download pretrained model"],"metadata":{"id":"fNH9m7ZNHf1q"}},{"cell_type":"code","source":["%cd /content/AICUP_Baseline_BoT-SORT/\n","!mkdir pretrained\n","%cd pretrained\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6e_training.pt"],"metadata":{"id":"bJ95Jq0n8V1d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718010082352,"user_tz":-480,"elapsed":2145,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"d0231744-9cc2-4931-8e56-4d7667811071"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/AICUP_Baseline_BoT-SORT\n","/content/AICUP_Baseline_BoT-SORT/pretrained\n","--2024-06-10 09:01:20--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6e_training.pt\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/09f75e19-59f2-4b43-9bda-39098e88345c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240610%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240610T090120Z&X-Amz-Expires=300&X-Amz-Signature=a0dbdde140aeeba34660fff08eff94e63055bd62a0416dee688416c6870f7c1c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-e6e_training.pt&response-content-type=application%2Foctet-stream [following]\n","--2024-06-10 09:01:20--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/09f75e19-59f2-4b43-9bda-39098e88345c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240610%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240610T090120Z&X-Amz-Expires=300&X-Amz-Signature=a0dbdde140aeeba34660fff08eff94e63055bd62a0416dee688416c6870f7c1c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-e6e_training.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 333898497 (318M) [application/octet-stream]\n","Saving to: ‘yolov7-e6e_training.pt’\n","\n","yolov7-e6e_training 100%[===================>] 318.43M   284MB/s    in 1.1s    \n","\n","2024-06-10 09:01:21 (284 MB/s) - ‘yolov7-e6e_training.pt’ saved [333898497/333898497]\n","\n"]}]},{"cell_type":"markdown","source":["Train re-ID model"],"metadata":{"id":"JGAj36YtMJIW"}},{"cell_type":"code","source":["%cd /content/AICUP_Baseline_BoT-SORT/\n","!python fast_reid/tools/train_net.py --config-file fast_reid/configs/AICUP/bagtricks_R50-ibn.yml MODEL.DEVICE \"cuda:0\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPmNZrf_L_3d","executionInfo":{"status":"ok","timestamp":1718010059496,"user_tz":-480,"elapsed":72165,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"13fd5eda-cf67-4bab-c94e-cd9f84fd218b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/AICUP_Baseline_BoT-SORT\n","2024-06-10 08:59:54.459141: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-10 08:59:54.459188: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-10 08:59:54.578210: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-10 08:59:54.795150: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-10 08:59:56.703440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Command Line Args: Namespace(config_file='fast_reid/configs/AICUP/bagtricks_R50-ibn.yml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49152', opts=['MODEL.DEVICE', 'cuda:0'])\n","\u001b[32m[06/10 09:00:01 fastreid]: \u001b[0mRank of current process: 0. World size: 1\n","\u001b[32m[06/10 09:00:03 fastreid]: \u001b[0mEnvironment info:\n","----------------------  -----------------------------------------------------------------\n","sys.platform            linux\n","Python                  3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n","numpy                   1.23.0\n","fastreid                failed to import\n","FASTREID_ENV_MODULE     <not set>\n","PyTorch                 2.3.0+cu121 @/usr/local/lib/python3.10/dist-packages/torch\n","PyTorch debug build     False\n","GPU available           True\n","GPU 0                   Tesla T4\n","CUDA_HOME               /usr/local/cuda\n","Pillow                  9.4.0\n","torchvision             0.18.0+cu121 @/usr/local/lib/python3.10/dist-packages/torchvision\n","torchvision arch flags  sm_50, sm_60, sm_70, sm_75, sm_80, sm_86, sm_90\n","cv2                     4.8.0\n","----------------------  -----------------------------------------------------------------\n","PyTorch built with:\n","  - GCC 9.3\n","  - C++ Version: 201703\n","  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX2\n","  - CUDA Runtime 12.2\n","  - Built with CUDA Runtime 12.1\n","  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n","  - CuDNN 8.9.6  (built against CUDA 12.2)\n","    - Built with CuDNN 8.9.2\n","  - Magma 2.6.1\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n","\n","\u001b[32m[06/10 09:00:03 fastreid]: \u001b[0mCommand line arguments: Namespace(config_file='fast_reid/configs/AICUP/bagtricks_R50-ibn.yml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:49152', opts=['MODEL.DEVICE', 'cuda:0'])\n","\u001b[32m[06/10 09:00:03 fastreid]: \u001b[0mContents of args.config_file=fast_reid/configs/AICUP/bagtricks_R50-ibn.yml:\n","_BASE_: ../Base-bagtricks.yml\n","\n","INPUT:\n","  SIZE_TRAIN: [256, 256]\n","  SIZE_TEST: [256, 256]\n","\n","MODEL:\n","  BACKBONE:\n","    WITH_IBN: True\n","  HEADS:\n","    POOL_LAYER: GeneralizedMeanPooling\n","\n","  LOSSES:\n","    TRI:\n","      HARD_MINING: False\n","      MARGIN: 0.0\n","\n","DATASETS:\n","  NAMES: (\"AICUP\",)\n","  TESTS: (\"AICUP\",)\n","\n","SOLVER:\n","  BIAS_LR_FACTOR: 1.\n","\n","  IMS_PER_BATCH: 256\n","  MAX_EPOCH: 60\n","  STEPS: [30, 50]\n","  WARMUP_ITERS: 2000\n","\n","  CHECKPOINT_PERIOD: 1\n","\n","TEST:\n","  EVAL_PERIOD: 60 # We didn't provide eval dataset （same as MAX_EPOCH）\n","  IMS_PER_BATCH: 256\n","\n","OUTPUT_DIR: logs/AICUP_115/bagtricks_R50-ibn\n","\n","\u001b[32m[06/10 09:00:03 fastreid]: \u001b[0mRunning with full config:\n","CUDNN_BENCHMARK: True\n","DATALOADER:\n","  NUM_INSTANCE: 4\n","  NUM_WORKERS: 8\n","  SAMPLER_TRAIN: NaiveIdentitySampler\n","  SET_WEIGHT: []\n","DATASETS:\n","  COMBINEALL: False\n","  NAMES: ('AICUP',)\n","  TESTS: ('AICUP',)\n","INPUT:\n","  AFFINE:\n","    ENABLED: False\n","  AUGMIX:\n","    ENABLED: False\n","    PROB: 0.0\n","  AUTOAUG:\n","    ENABLED: False\n","    PROB: 0.0\n","  CJ:\n","    BRIGHTNESS: 0.15\n","    CONTRAST: 0.15\n","    ENABLED: False\n","    HUE: 0.1\n","    PROB: 0.5\n","    SATURATION: 0.1\n","  CROP:\n","    ENABLED: False\n","    RATIO: [0.75, 1.3333333333333333]\n","    SCALE: [0.16, 1]\n","    SIZE: [224, 224]\n","  FLIP:\n","    ENABLED: True\n","    PROB: 0.5\n","  PADDING:\n","    ENABLED: True\n","    MODE: constant\n","    SIZE: 10\n","  REA:\n","    ENABLED: True\n","    PROB: 0.5\n","    VALUE: [123.675, 116.28, 103.53]\n","  RPT:\n","    ENABLED: False\n","    PROB: 0.5\n","  SIZE_TEST: [256, 256]\n","  SIZE_TRAIN: [256, 256]\n","KD:\n","  EMA:\n","    ENABLED: False\n","    MOMENTUM: 0.999\n","  MODEL_CONFIG: []\n","  MODEL_WEIGHTS: []\n","MODEL:\n","  BACKBONE:\n","    ATT_DROP_RATE: 0.0\n","    DEPTH: 50x\n","    DROP_PATH_RATIO: 0.1\n","    DROP_RATIO: 0.0\n","    FEAT_DIM: 2048\n","    LAST_STRIDE: 1\n","    NAME: build_resnet_backbone\n","    NORM: BN\n","    PRETRAIN: True\n","    PRETRAIN_PATH: \n","    SIE_COE: 3.0\n","    STRIDE_SIZE: (16, 16)\n","    WITH_IBN: True\n","    WITH_NL: False\n","    WITH_SE: False\n","  DEVICE: cuda:0\n","  FREEZE_LAYERS: []\n","  HEADS:\n","    CLS_LAYER: Linear\n","    EMBEDDING_DIM: 0\n","    MARGIN: 0.0\n","    NAME: EmbeddingHead\n","    NECK_FEAT: before\n","    NORM: BN\n","    NUM_CLASSES: 0\n","    POOL_LAYER: GeneralizedMeanPooling\n","    SCALE: 1\n","    WITH_BNNECK: True\n","  LOSSES:\n","    CE:\n","      ALPHA: 0.2\n","      EPSILON: 0.1\n","      SCALE: 1.0\n","    CIRCLE:\n","      GAMMA: 128\n","      MARGIN: 0.25\n","      SCALE: 1.0\n","    COSFACE:\n","      GAMMA: 128\n","      MARGIN: 0.25\n","      SCALE: 1.0\n","    FL:\n","      ALPHA: 0.25\n","      GAMMA: 2\n","      SCALE: 1.0\n","    NAME: ('CrossEntropyLoss', 'TripletLoss')\n","    TRI:\n","      HARD_MINING: False\n","      MARGIN: 0.0\n","      NORM_FEAT: False\n","      SCALE: 1.0\n","  META_ARCHITECTURE: Baseline\n","  PIXEL_MEAN: [123.675, 116.28, 103.53]\n","  PIXEL_STD: [58.395, 57.120000000000005, 57.375]\n","  QUEUE_SIZE: 8192\n","  WEIGHTS: \n","OUTPUT_DIR: logs/AICUP_115/bagtricks_R50-ibn\n","SOLVER:\n","  AMP:\n","    ENABLED: True\n","  BASE_LR: 0.00035\n","  BIAS_LR_FACTOR: 1.0\n","  CHECKPOINT_PERIOD: 1\n","  CLIP_GRADIENTS:\n","    CLIP_TYPE: norm\n","    CLIP_VALUE: 5.0\n","    ENABLED: False\n","    NORM_TYPE: 2.0\n","  DELAY_EPOCHS: 0\n","  ETA_MIN_LR: 1e-07\n","  FREEZE_ITERS: 0\n","  GAMMA: 0.1\n","  HEADS_LR_FACTOR: 1.0\n","  IMS_PER_BATCH: 256\n","  MAX_EPOCH: 60\n","  MOMENTUM: 0.9\n","  NESTEROV: False\n","  OPT: Adam\n","  SCHED: MultiStepLR\n","  STEPS: [30, 50]\n","  WARMUP_FACTOR: 0.1\n","  WARMUP_ITERS: 2000\n","  WARMUP_METHOD: linear\n","  WEIGHT_DECAY: 0.0005\n","  WEIGHT_DECAY_BIAS: 0.0005\n","  WEIGHT_DECAY_NORM: 0.0005\n","TEST:\n","  AQE:\n","    ALPHA: 3.0\n","    ENABLED: False\n","    QE_K: 5\n","    QE_TIME: 1\n","  EVAL_PERIOD: 60\n","  FLIP:\n","    ENABLED: False\n","  IMS_PER_BATCH: 256\n","  METRIC: cosine\n","  PRECISE_BN:\n","    DATASET: Market1501\n","    ENABLED: False\n","    NUM_ITER: 300\n","  RERANK:\n","    ENABLED: False\n","    K1: 20\n","    K2: 6\n","    LAMBDA: 0.3\n","  ROC:\n","    ENABLED: False\n","\u001b[32m[06/10 09:00:03 fastreid]: \u001b[0mFull config saved to /content/AICUP_Baseline_BoT-SORT/logs/AICUP_115/bagtricks_R50-ibn/config.yaml\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Downloading...\n","From: https://github.com/XingangPan/IBN-Net/releases/download/v1.0/resnet50_ibn_a-d9d0bb7b.pth\n","To: /root/.cache/torch/checkpoints/resnet50_ibn_a-d9d0bb7b.pth\n","100% 102M/102M [00:01<00:00, 102MB/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/data/transforms/functional.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n","/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/data/transforms/functional.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n","/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/data/transforms/functional.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n","/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/data/transforms/functional.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n","/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/data/transforms/functional.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n","/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/data/transforms/functional.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n","/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/data/transforms/functional.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n","/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/data/transforms/functional.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n","start epoch 0\n","Exception during training:\n","Traceback (most recent call last):\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/engine/train_loop.py\", line 146, in train\n","    self.run_step()\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/engine/defaults.py\", line 359, in run_step\n","    self._trainer.run_step()\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/engine/train_loop.py\", line 346, in run_step\n","    loss_dict = self.model(data)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/modeling/meta_arch/baseline.py\", line 101, in forward\n","    features = self.backbone(images)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/modeling/backbones/resnet.py\", line 223, in forward\n","    x = self.layer4[i](x)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/modeling/backbones/resnet.py\", line 119, in forward\n","    residual = self.downsample(x)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 217, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 460, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n","    return F.conv2d(input, weight, bias, self.stride,\n","torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU \n","Traceback (most recent call last):\n","  File \"/content/AICUP_Baseline_BoT-SORT/fast_reid/tools/train_net.py\", line 54, in <module>\n","    launch(\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/engine/launch.py\", line 71, in launch\n","    main_func(*args)\n","  File \"/content/AICUP_Baseline_BoT-SORT/fast_reid/tools/train_net.py\", line 47, in main\n","    return trainer.train()\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/engine/defaults.py\", line 350, in train\n","    super().train(self.start_epoch, self.max_epoch, self.iters_per_epoch)\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/engine/train_loop.py\", line 146, in train\n","    self.run_step()\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/engine/defaults.py\", line 359, in run_step\n","    self._trainer.run_step()\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/engine/train_loop.py\", line 346, in run_step\n","    loss_dict = self.model(data)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/modeling/meta_arch/baseline.py\", line 101, in forward\n","    features = self.backbone(images)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/modeling/backbones/resnet.py\", line 223, in forward\n","    x = self.layer4[i](x)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/AICUP_Baseline_BoT-SORT/./fast_reid/fastreid/modeling/backbones/resnet.py\", line 119, in forward\n","    residual = self.downsample(x)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 217, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 460, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n","    return F.conv2d(input, weight, bias, self.stride,\n","torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU \n"]}]},{"cell_type":"markdown","source":["Train object detection model"],"metadata":{"id":"U8D1uR60Plq-"}},{"cell_type":"code","source":["%cd /content/AICUP_Baseline_BoT-SORT/\n","!python yolov7/train.py --device 0 --batch-size 16 --epochs 50 --data yolov7/data/AICUP.yaml --img 1280 1280 --cfg yolov7/cfg/training/yolov7-AICUP.yaml --weights 'pretrained/yolov7-e6e_training.pt' --name yolov7-AICUP --hyp data/hyp.scratch.custom.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QiYlAvI5PmTy","executionInfo":{"status":"ok","timestamp":1718010183001,"user_tz":-480,"elapsed":96783,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"7b83bccc-27a6-44b2-c203-5f3b77e63349"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/AICUP_Baseline_BoT-SORT\n","2024-06-10 09:01:31.484951: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-10 09:01:31.485000: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-10 09:01:31.492727: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-10 09:01:31.510386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-10 09:01:33.425819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOv7 🚀 0d5b814 torch 2.3.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","Namespace(weights='pretrained/yolov7-e6e_training.pt', cfg='yolov7/cfg/training/yolov7-AICUP.yaml', data='yolov7/data/AICUP.yaml', hyp='./yolov7/data/hyp.scratch.custom.yaml', epochs=50, batch_size=16, img_size=[1280, 1280], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='yolov7-AICUP', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', world_size=1, global_rank=-1, save_dir='runs/train/yolov7-AICUP', total_batch_size=16)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  yolov7.models.common.Conv               [3, 32, 3, 1]                 \n","  1                -1  1     18560  yolov7.models.common.Conv               [32, 64, 3, 2]                \n","  2                -1  1     36992  yolov7.models.common.Conv               [64, 64, 3, 1]                \n","  3                -1  1     73984  yolov7.models.common.Conv               [64, 128, 3, 2]               \n","  4                -1  1      8320  yolov7.models.common.Conv               [128, 64, 1, 1]               \n","  5                -2  1      8320  yolov7.models.common.Conv               [128, 64, 1, 1]               \n","  6                -1  1     36992  yolov7.models.common.Conv               [64, 64, 3, 1]                \n","  7                -1  1     36992  yolov7.models.common.Conv               [64, 64, 3, 1]                \n","  8                -1  1     36992  yolov7.models.common.Conv               [64, 64, 3, 1]                \n","  9                -1  1     36992  yolov7.models.common.Conv               [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  yolov7.models.common.Conv               [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  yolov7.models.common.Conv               [256, 128, 1, 1]              \n"," 14                -3  1     33024  yolov7.models.common.Conv               [256, 128, 1, 1]              \n"," 15                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  yolov7.models.common.Conv               [256, 128, 1, 1]              \n"," 18                -2  1     33024  yolov7.models.common.Conv               [256, 128, 1, 1]              \n"," 19                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 1]              \n"," 20                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 1]              \n"," 21                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 1]              \n"," 22                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  yolov7.models.common.Conv               [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  yolov7.models.common.Conv               [512, 256, 1, 1]              \n"," 27                -3  1    131584  yolov7.models.common.Conv               [512, 256, 1, 1]              \n"," 28                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  yolov7.models.common.Conv               [512, 256, 1, 1]              \n"," 31                -2  1    131584  yolov7.models.common.Conv               [512, 256, 1, 1]              \n"," 32                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n"," 33                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n"," 34                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n"," 35                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  yolov7.models.common.Conv               [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  yolov7.models.common.Conv               [1024, 512, 1, 1]             \n"," 40                -3  1    525312  yolov7.models.common.Conv               [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  yolov7.models.common.Conv               [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  yolov7.models.common.Conv               [1024, 256, 1, 1]             \n"," 44                -2  1    262656  yolov7.models.common.Conv               [1024, 256, 1, 1]             \n"," 45                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n"," 46                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n"," 47                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n"," 48                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  yolov7.models.common.Conv               [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  yolov7.models.common.Conv               [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  yolov7.models.common.Conv               [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  yolov7.models.common.Conv               [512, 256, 1, 1]              \n"," 57                -2  1    131584  yolov7.models.common.Conv               [512, 256, 1, 1]              \n"," 58                -1  1    295168  yolov7.models.common.Conv               [256, 128, 3, 1]              \n"," 59                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 1]              \n"," 60                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 1]              \n"," 61                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  yolov7.models.common.Conv               [1024, 256, 1, 1]             \n"," 64                -1  1     33024  yolov7.models.common.Conv               [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  yolov7.models.common.Conv               [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  yolov7.models.common.Conv               [256, 128, 1, 1]              \n"," 69                -2  1     33024  yolov7.models.common.Conv               [256, 128, 1, 1]              \n"," 70                -1  1     73856  yolov7.models.common.Conv               [128, 64, 3, 1]               \n"," 71                -1  1     36992  yolov7.models.common.Conv               [64, 64, 3, 1]                \n"," 72                -1  1     36992  yolov7.models.common.Conv               [64, 64, 3, 1]                \n"," 73                -1  1     36992  yolov7.models.common.Conv               [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  yolov7.models.common.Conv               [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  yolov7.models.common.Conv               [128, 128, 1, 1]              \n"," 78                -3  1     16640  yolov7.models.common.Conv               [128, 128, 1, 1]              \n"," 79                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  yolov7.models.common.Conv               [512, 256, 1, 1]              \n"," 82                -2  1    131584  yolov7.models.common.Conv               [512, 256, 1, 1]              \n"," 83                -1  1    295168  yolov7.models.common.Conv               [256, 128, 3, 1]              \n"," 84                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 1]              \n"," 85                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 1]              \n"," 86                -1  1    147712  yolov7.models.common.Conv               [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  yolov7.models.common.Conv               [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  yolov7.models.common.Conv               [256, 256, 1, 1]              \n"," 91                -3  1     66048  yolov7.models.common.Conv               [256, 256, 1, 1]              \n"," 92                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  yolov7.models.common.Conv               [1024, 512, 1, 1]             \n"," 95                -2  1    525312  yolov7.models.common.Conv               [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  yolov7.models.common.Conv               [512, 256, 3, 1]              \n"," 97                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n"," 98                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n"," 99                -1  1    590336  yolov7.models.common.Conv               [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  yolov7.models.common.Conv               [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","Model Summary: 415 layers, 37196556 parameters, 37196556 gradients\n","\n","Transferred 130/566 items from pretrained/yolov7-e6e_training.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/AI_CUP_MCMOT_dataset/yolo/train/labels' images and labels... 23307 found, 0 missing, 7374 empty, 0 corrupted: 100% 23307/23307 [00:42<00:00, 543.37it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/AI_CUP_MCMOT_dataset/yolo/train/labels.cache\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/AI_CUP_MCMOT_dataset/yolo/valid/labels' images and labels... 8640 found, 0 missing, 3248 empty, 0 corrupted: 100% 8640/8640 [00:16<00:00, 518.96it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/AI_CUP_MCMOT_dataset/yolo/valid/labels.cache\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.29, Best Possible Recall (BPR) = 1.0000\n","Image sizes 1280 train, 1280 test\n","Using 2 dataloader workers\n","Logging results to runs/train/yolov7-AICUP\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","  0% 0/1457 [00:14<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"/content/AICUP_Baseline_BoT-SORT/yolov7/train.py\", line 613, in <module>\n","    train(hyp, opt, device, tb_writer)\n","  File \"/content/AICUP_Baseline_BoT-SORT/yolov7/train.py\", line 365, in train\n","    pred = model(imgs)  # forward\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/AICUP_Baseline_BoT-SORT/./yolov7/models/yolo.py\", line 514, in forward\n","    return self.forward_once(x, profile)  # single-scale inference, train\n","  File \"/content/AICUP_Baseline_BoT-SORT/./yolov7/models/yolo.py\", line 540, in forward_once\n","    x = m(x)  # run\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/AICUP_Baseline_BoT-SORT/./yolov7/models/common.py\", line 108, in forward\n","    return self.act(self.bn(self.conv(x)))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\", line 175, in forward\n","    return F.batch_norm(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2509, in batch_norm\n","    return torch.batch_norm(\n","torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 200.00 MiB. GPU \n"]}]},{"cell_type":"markdown","source":["# Tracking"],"metadata":{"id":"zJX3JmevQPXp"}},{"cell_type":"markdown","source":["Download model trained by ourselves"],"metadata":{"id":"PugRQTDHVD7x"}},{"cell_type":"code","source":["%cd /content/AICUP_Baseline_BoT-SORT/pretrained\n","!wget -O model_0058.pth https://www.dropbox.com/scl/fi/2vlmbulgq7axw1bi04wnc/model_0058.pth?rlkey=44j68knaa5oqd064va22y8pth&st=7ysurk0q&dl=1\n","!wget -O best.pt https://www.dropbox.com/scl/fi/3o9r9ia4wpwrtoa0fhgfi/best.pt?rlkey=zplb9w5zmy2lnz0izr4hq3c2x&st=616ss0ui&dl=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J3ETWnQlVep5","executionInfo":{"status":"ok","timestamp":1718011895213,"user_tz":-480,"elapsed":11031,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"671f90b5-15f6-407b-c231-69ee9803518c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/AICUP_Baseline_BoT-SORT/pretrained\n","--2024-06-10 09:31:23--  https://www.dropbox.com/scl/fi/2vlmbulgq7axw1bi04wnc/model_0058.pth?rlkey=44j68knaa5oqd064va22y8pth\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucfbd81f0e1a4cd233744c3aadd1.dl.dropboxusercontent.com/cd/0/inline/CUhK2i6qZpLYfk0ndcZ35CKBNoXGwt1v303rOZKhjN0owIgcGtgUXYokDNuGj4QsIsOrULIv9lC0JQ1NDz25blzAD6RXmwknDroZZXMDPxmfJT8ZzIjmzIDovr5g6LukjFKaV4ChRMJy1JVfnmem-u7d/file# [following]\n","--2024-06-10 09:31:24--  https://ucfbd81f0e1a4cd233744c3aadd1.dl.dropboxusercontent.com/cd/0/inline/CUhK2i6qZpLYfk0ndcZ35CKBNoXGwt1v303rOZKhjN0owIgcGtgUXYokDNuGj4QsIsOrULIv9lC0JQ1NDz25blzAD6RXmwknDroZZXMDPxmfJT8ZzIjmzIDovr5g6LukjFKaV4ChRMJy1JVfnmem-u7d/file\n","Resolving ucfbd81f0e1a4cd233744c3aadd1.dl.dropboxusercontent.com (ucfbd81f0e1a4cd233744c3aadd1.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to ucfbd81f0e1a4cd233744c3aadd1.dl.dropboxusercontent.com (ucfbd81f0e1a4cd233744c3aadd1.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/CUgMTtPTaw7BvnPqnLFZGgJFBwegL2lma1RhRbrHhQWMexWHqqitPDmNpI0WiKJDQAabApEuw_AkO0Sd2PQjK3arD-V8fzBTu-BcSOguXJr9l3_L_zmEExtDXrhgZBrXV_c8AIzjcSPCcxoNMD3nyy5XkwOd2H5DaSZEIwlgbCHu3dTwrvi_GERVVcyo8mtQN68PNz8G11Uqb5uVd-uYWXAmZa-pjj7inZryCpsSBP_fd0yrRSYaA8_-dzGSMYAOVpgZPWAg5nia9OZvDbIp30HxpCOI3vke-fVY1aBl3a-3l5Bm6LAF6A0cwQEaedj6Zy1v__WY8pV--ZDBwdKIeVhx-JEvYA2S2hfsBI48_3-AxXZyPwlWGwK2eIku9xSeOGQ/file [following]\n","--2024-06-10 09:31:25--  https://ucfbd81f0e1a4cd233744c3aadd1.dl.dropboxusercontent.com/cd/0/inline2/CUgMTtPTaw7BvnPqnLFZGgJFBwegL2lma1RhRbrHhQWMexWHqqitPDmNpI0WiKJDQAabApEuw_AkO0Sd2PQjK3arD-V8fzBTu-BcSOguXJr9l3_L_zmEExtDXrhgZBrXV_c8AIzjcSPCcxoNMD3nyy5XkwOd2H5DaSZEIwlgbCHu3dTwrvi_GERVVcyo8mtQN68PNz8G11Uqb5uVd-uYWXAmZa-pjj7inZryCpsSBP_fd0yrRSYaA8_-dzGSMYAOVpgZPWAg5nia9OZvDbIp30HxpCOI3vke-fVY1aBl3a-3l5Bm6LAF6A0cwQEaedj6Zy1v__WY8pV--ZDBwdKIeVhx-JEvYA2S2hfsBI48_3-AxXZyPwlWGwK2eIku9xSeOGQ/file\n","Reusing existing connection to ucfbd81f0e1a4cd233744c3aadd1.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 374569653 (357M) [application/octet-stream]\n","Saving to: ‘model_0058.pth’\n","\n","model_0058.pth      100%[===================>] 357.22M   113MB/s    in 3.3s    \n","\n","2024-06-10 09:31:29 (109 MB/s) - ‘model_0058.pth’ saved [374569653/374569653]\n","\n","--2024-06-10 09:31:29--  https://www.dropbox.com/scl/fi/i69xxqmfhvz91qafztr2z/epoch_049.pt?rlkey=46ncq9z8zqmscejn29vsxs4zo\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uca83ea65a23fb17609977998d6a.dl.dropboxusercontent.com/cd/0/inline/CUi49O8i1IrQEjo6Jb8mWOs6Z7gC0k12TGPB0vANU7Ki2elYfibIEn9R7O-acSIhNRdMv3fyHBEQnQziCTsR-Ri1no5JG3801md0lhIjzk9Q0nSunbGjkldBgLHn5nKiHyjgstBJy_kTmQrMLhvmATUb/file# [following]\n","--2024-06-10 09:31:29--  https://uca83ea65a23fb17609977998d6a.dl.dropboxusercontent.com/cd/0/inline/CUi49O8i1IrQEjo6Jb8mWOs6Z7gC0k12TGPB0vANU7Ki2elYfibIEn9R7O-acSIhNRdMv3fyHBEQnQziCTsR-Ri1no5JG3801md0lhIjzk9Q0nSunbGjkldBgLHn5nKiHyjgstBJy_kTmQrMLhvmATUb/file\n","Resolving uca83ea65a23fb17609977998d6a.dl.dropboxusercontent.com (uca83ea65a23fb17609977998d6a.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to uca83ea65a23fb17609977998d6a.dl.dropboxusercontent.com (uca83ea65a23fb17609977998d6a.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/CUiJRMzEgJyqqCKN_gfBVl26KE1gvvqVCWF9NUk57m1wPW1jdV3XYihUt_ARX8hpB7znaJ_GbbZAj-ffduttsKSaS9tA1CkhRyea91MvJWoATlWz0hMTLLJ1NuOtwcO0evPbPgIxapKvrYXqcIwBYfxKKCv3ElEqC6jEk4IW9J8VJAa7OqkGn6H430S6t1HsDZBHzIXZUSoI0WxkDtMRuZQeJ60mg45z9NvuArOXgoWmPRCGA4MzpucQoJ5MmZD9sYShMtjNYT53mVLfTUvwJ4e4ExHNKRDg1-BmNHK-Xk-Lg2d42yOApYpwWNu3GqeuUBFvtmCCOwI5ssLwnWL8N0DwTc5bTupxNh4qwQccpE4OIfas-0CM35TC1oQF8jmkto8/file [following]\n","--2024-06-10 09:31:30--  https://uca83ea65a23fb17609977998d6a.dl.dropboxusercontent.com/cd/0/inline2/CUiJRMzEgJyqqCKN_gfBVl26KE1gvvqVCWF9NUk57m1wPW1jdV3XYihUt_ARX8hpB7znaJ_GbbZAj-ffduttsKSaS9tA1CkhRyea91MvJWoATlWz0hMTLLJ1NuOtwcO0evPbPgIxapKvrYXqcIwBYfxKKCv3ElEqC6jEk4IW9J8VJAa7OqkGn6H430S6t1HsDZBHzIXZUSoI0WxkDtMRuZQeJ60mg45z9NvuArOXgoWmPRCGA4MzpucQoJ5MmZD9sYShMtjNYT53mVLfTUvwJ4e4ExHNKRDg1-BmNHK-Xk-Lg2d42yOApYpwWNu3GqeuUBFvtmCCOwI5ssLwnWL8N0DwTc5bTupxNh4qwQccpE4OIfas-0CM35TC1oQF8jmkto8/file\n","Reusing existing connection to uca83ea65a23fb17609977998d6a.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 298519684 (285M) [application/octet-stream]\n","Saving to: ‘best.pt’\n","\n","best.pt             100%[===================>] 284.69M  80.6MB/s    in 3.5s    \n","\n","2024-06-10 09:31:34 (80.6 MB/s) - ‘best.pt’ saved [298519684/298519684]\n","\n"]}]},{"cell_type":"markdown","source":["Track one timestamp"],"metadata":{"id":"mlS4M_sEaPMQ"}},{"cell_type":"code","source":["%cd /content/AICUP_Baseline_BoT-SORT/\n","!python tools/mc_demo_yolov7.py --weights pretrained/best.pt --source /content/AI_CUP_MCMOT_dataset/train/images/0902_150000_151900 --device \"0\" --name \"0902_150000_151900\" --fuse-score --agnostic-nms --with-reid --fast-reid-config fast_reid/configs/AICUP/bagtricks_R50-ibn.yml --fast-reid-weights pretrained/model_0058.pth"],"metadata":{"id":"mbsY3X-GPw2K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718011917713,"user_tz":-480,"elapsed":16975,"user":{"displayName":"related AI","userId":"06493667994409210616"}},"outputId":"4d2e91fa-6137-4fd2-c35f-e7a7b7d800fc"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/AICUP_Baseline_BoT-SORT\n","2024-06-10 09:31:44.563053: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-10 09:31:44.563113: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-10 09:31:44.564548: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-10 09:31:44.571899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-10 09:31:46.049047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Namespace(weights=['pretrained/best.pt'], source='/content/AI_CUP_MCMOT_dataset/train/images/0902_150000_151900', img_size=1920, conf_thres=0.09, iou_thres=0.7, device='0', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=True, augment=False, update=False, project='runs/detect', name='0902_150000_151900', exist_ok=False, trace=False, hide_labels_name=False, track_high_thresh=0.3, track_low_thresh=0.05, new_track_thresh=0.4, track_buffer=30, match_thresh=0.7, aspect_ratio_thresh=1.6, min_box_area=10, mot20=True, cmc_method='sparseOptFlow', with_reid=True, fast_reid_config='fast_reid/configs/AICUP/bagtricks_R50-ibn.yml', fast_reid_weights='pretrained/model_0058.pth', proximity_thresh=0.5, appearance_thresh=0.25, jde=False, ablation=False)\n","YOLOv7 🚀 0d5b814 torch 2.3.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","IDetect.fuse\n","Model Summary: 321 layers, 36485356 parameters, 6194944 gradients\n","Loading checkpoint from pretrained/model_0058.pth\n","Skip loading parameter 'heads.weight' to the model due to incompatible shapes: (3749, 2048) in the checkpoint but (0, 2048) in the model! You might want to double check if this is expected.\n","Some model parameters or buffers are not found in the checkpoint:\n","  \u001b[34mheads.weight\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","tracking 0902_150000_151900:   0% 0/2880 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","tracking 0902_150000_151900:   1% 35/2880 [00:05<07:19,  6.47it/s]\n","Traceback (most recent call last):\n","  File \"/content/AICUP_Baseline_BoT-SORT/tools/mc_demo_yolov7.py\", line 253, in <module>\n","    detect()\n","  File \"/content/AICUP_Baseline_BoT-SORT/tools/mc_demo_yolov7.py\", line 99, in detect\n","    pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n","  File \"/content/AICUP_Baseline_BoT-SORT/./yolov7/utils/general.py\", line 635, in non_max_suppression\n","    if labels and len(labels[xi]):\n","KeyboardInterrupt\n","^C\n"]}]}]}